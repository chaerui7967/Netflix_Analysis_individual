{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "점수 예측모델_데이터 전처리ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPRMlYbMzZY9uu9iqAHG0R1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaerui7967/Netflix_Analysis_individual/blob/master/%EC%A0%90%EC%88%98_%EC%98%88%EC%B8%A1%EB%AA%A8%EB%8D%B8_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A0%84%EC%B2%98%EB%A6%ACipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac9gEBTdXCR7"
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno # 널값 바차트로 시각화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWWQxvmdXPxj"
      },
      "source": [
        "netflix = pd.read_csv('./use_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5WzMOnX7y8"
      },
      "source": [
        "netflix.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22gqaaxRYXPz"
      },
      "source": [
        "netflix.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frc4rmJ4YDia"
      },
      "source": [
        "df_net = netflix.drop(columns = ['Unnamed: 0'],axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOKlgeIRYjaD"
      },
      "source": [
        "df_net.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHzOzExpY1Oq"
      },
      "source": [
        "color= ['dimgrey','dimgrey','blue','blue','blue','dimgrey','blue','blue','blue','blue','blue',\n",
        "        'dimgrey','blue','blue','blue','blue','blue','blue','blue','blue','blue','blue','dimgrey',\n",
        "        'blue','blue','blue']\n",
        "missingno.bar(df_net,fontsize=10,color=color,figsize=(10,5))\n",
        "plt.title('COLUMN MISSING VALUES',fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6nBF3QVvjhS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SCCwsTiad2X"
      },
      "source": [
        "viewpoint 예측에 사용될 변수들을 일단은 국가와 장르, 태그, 언어, 출시 일, 런타임을 가지고 먼저 예측초기모델을 만들어보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt8iQSKovkvA"
      },
      "source": [
        "null값 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEcOB3lOaQAC"
      },
      "source": [
        "df = df_net[['Series or Movie','COUNTRY', 'Release Date', 'GENRE', 'Tags', 'Languages', 'Runtime']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOlp8b1dvLPv"
      },
      "source": [
        "df_taget = df_net['VALUE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2aCmKDSwGV_"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FjwDPTPyjnB"
      },
      "source": [
        "df['Release Date'] = df['Release Date'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JavTJS9fwKjY"
      },
      "source": [
        "df = df.fillna('NA')  # null값을 모두 'NA'으로 치환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjEmt66swz4R"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od9Nlizlra-z"
      },
      "source": [
        "### Release Date는 년도만 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPr4HXp9raXC"
      },
      "source": [
        "df[\"Release Date\"] = pd.to_datetime(df['Release Date'])\n",
        "df['Year'] = df['Release Date'].dt.year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGvQAefbtbEu"
      },
      "source": [
        "df = df.drop(columns = ['Release Date'],axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a6p2215tmY1"
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFRNCqy1sZR_"
      },
      "source": [
        "# 변수들을 원핫 인코딩으로 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVU31mMpsY11"
      },
      "source": [
        "pd_df = pd.get_dummies(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4iuLNPG1yjF"
      },
      "source": [
        "## 딥러닝을 통해 모든 변수들을 넣고 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCAgRBPeqRFq"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm6g-SpjucIj"
      },
      "source": [
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(pd_df.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUuKqnEuz4D"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "\n",
        "num_val_samples = len(pd_df) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('처리중인 폴드 #', i)\n",
        "    val_data = pd_df[i * num_val_samples: (i + 1) * num_val_samples]  # 검증 데이터 준비: k번째 분할\n",
        "    val_targets = df_taget[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate(  # 훈련 데이터 준비: 다른 분할 전체\n",
        "        [pd_df[:i * num_val_samples],\n",
        "         pd_df[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [df_taget[:i * num_val_samples],\n",
        "         df_taget[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "model = build_model()  # 케라스 모델 구성(컴파일 포함)\n",
        "model.fit(partial_train_data, partial_train_targets,  # 모델 훈련(verbose=0이므로 훈련 과정이 출력되지 않습니다.)\n",
        "          epochs=num_epochs, batch_size=1, verbose=0)\n",
        "val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)  # 검증 세트로 모델 평가\n",
        "all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ2sK-HJzaK8"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhdFJ5h_88rP"
      },
      "source": [
        "**에포크 100으로 딥러닝을 진행했을 때 오차가 490으로 viewpoint가 1~40000인것을 감안하면 오차가 좀 큰걸로 나옴**\n",
        "- all_scores = [490.316650390625]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfoJj71zaIE"
      },
      "source": [
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print('처리중인 폴드 #', i)\n",
        "    val_data = pd_df[i * num_val_samples: (i + 1) * num_val_samples]  #검증 데이터 준비: k번째 분할    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(  # 훈련 데이터 준비: 다른 분할 전체\n",
        "        [pd_df[:i * num_val_samples],\n",
        "         pd_df[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [df_taget[:i * num_val_samples],\n",
        "         df_taget[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "model = build_model()  # 케라스 모델 구성(컴파일 포함)\n",
        "history = model.fit(partial_train_data, partial_train_targets,  # 모델 훈련(verbose=0이므로 훈련 과정이 출력되지 않습니다.)\n",
        "                    validation_data=(val_data, val_targets),\n",
        "                    epochs=num_epochs, batch_size=1, verbose=0)\n",
        "# mae_history = history.history['val_mae']\n",
        "# all_mae_histories.append(mae_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWn5ITwsBY77"
      },
      "source": [
        "mae_history = history.history['val_mae']\n",
        "all_mae_histories.append(mae_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh-2gGzazaFG"
      },
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1W_94tUzaBS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD5wO9sezZ-t"
      },
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "\n",
        "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKJ9sg-ezZvG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm04o6bXzZrN"
      },
      "source": [
        "model = build_model()  # 새롭게 컴파일된 모델을 얻습니다.\n",
        "model.fit(pd_df, df_taget,  # 전체 데이터로 훈련시킵니다.\n",
        "          epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(pd_df, df_taget)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D4m8XrRCqUr"
      },
      "source": [
        "94/94 [==============================] - 1s 2ms/step - loss: 4435821.0000 - mae: 753.8995"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzHhvDJNCtjy"
      },
      "source": [
        "test_mae_score = 753.8995361328125"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5YL_F9x2z_L"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvK7bz3A2z8g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4peD-Me2z5m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE4e9lJ_XXJ2"
      },
      "source": [
        "# pd_df = pd.get_dummies(df_net['Tags'])\n",
        "# df_result = pd.concat([df_net, pd_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6w3gvNbfYa9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-HKWcVbfaNz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}